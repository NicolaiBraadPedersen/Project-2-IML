library(data.table)
library(ggplot2)
library(mlr3)
library(mlr3learners)
library(mlr3tuning)
library(mlr3mbo)
library(glmnet)
library(OpenML)
library(mlr3pipelines)
library(mlr3filters)
library(tidyr)
library(dplyr)
library(glex)
library(xgboost)
library(patchwork)
library(DALEX)
library(DALEXtra)


set.seed(732)

future::plan("multisession")
data = fread("Motor vehicle insurance data.csv")

cond_1 = which(data$Distribution_channel != 1 & data$Distribution_channel != 0)
data$Distribution_channel[cond_1] = matrix(data= NA, nrow=length(cond_1))

#Initialize data
data$ID = as.numeric(data$ID)
data$Distribution_channel = as.numeric(data$Distribution_channel)
data$Payment = as.numeric(data$Payment)
data$Type_risk = as.numeric(data$Type_risk)
data$Area = as.numeric(data$Area)
data$Second_driver = as.numeric(data$Second_driver)
data$N_doors = as.numeric(data$N_doors)
data$Type_fuel = as.numeric(ifelse(data$Type_fuel == "P", 1, ifelse(data$Type_fuel == "D", 0, data$Type_fuel)))

data$Date_start_contract = as.Date(data$Date_start_contract, format = "%d/%m/%Y")
data$Date_start_contract = as.numeric(data$Date_start_contract)
data$Date_birth = as.Date(data$Date_birth, format = "%d/%m/%Y")
data$Date_birth = as.numeric(data$Date_birth)
data$Date_driving_licence = as.Date(data$Date_driving_licence, format = "%d/%m/%Y")
data$Date_driving_licence = as.numeric(data$Date_driving_licence)

data_num = data[,lapply(.SD, mean, na.rm = TRUE), by = ID, .SDcols = is.numeric]
data_num = data_num[,-c("Lapse", "Premium", "N_claims_year", "N_claims_history","R_Claims_history")]
data = data_num[,-c(1,2)]
rm(data_fac,data_num,cond_1)

data[is.na(get("Length")),("Length"):=mean(data[["Length"]],na.rm=TRUE)]
data[is.na(get("Distribution_channel")), 
       ("Distribution_channel") := sample(data[!is.na(get("Distribution_channel")), get("Distribution_channel")],
                                          .N, replace = TRUE)]
data[is.na(get("Type_fuel")), 
       ("Type_fuel") := sample(data[!is.na(get("Type_fuel")), get("Type_fuel")],
                               .N, replace = TRUE)]



task_tweedie = as_task_regr(data, target="Cost_claims_year")

lrn_featureless = as_learner(lrn("regr.featureless"))
lrn_tweedie = as_learner(graph %>>% lrn("regr.xgboost", objective="reg:tweedie", max_depth=2, 
                                        nrounds=to_tune(100,500), 
                                        eta = to_tune(0.1,0.3), 
                                        tweedie_variance_power = to_tune(1,2)) )

at_tweedie = auto_tuner(tuner = tnr("random_search", batch_size = 8),
                        learner = lrn_tweedie,
                        resampling = rsmp("cv", folds = 5),
                        measure = msr("regr.mae"),
                        terminator = trm("evals", n_evals = 10))


#at_tweedie$train(task_tweedie)
#at_tweedie$archive$best()

best_tweedie = as_learner(lrn("regr.xgboost", objective="reg:tweedie", max_depth=2,
                                         nrounds = 348, 
                                         eta = 0.1869081,
                                         tweedie_variance_power = 1.667094))

best_tweedie$train(task_tweedie)

design_tweedie = benchmark_grid(
  tasks = task_tweedie, 
  learners = list(best_tweedie, lrn_featureless),
  resamplings = rsmp("cv", folds=3)
)

results = benchmark(design = design_tweedie)

results$aggregate(list(msr("regr.mse"),msr("regr.mae")))
